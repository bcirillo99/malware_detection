# AI for cyber security 2022/23
# Authors:
# - Cirillo Benedetto 
# - Montervino Dario 
# - Salzano Simone
# - Tisi Andrea

import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import DataLoader, random_split
from torchvision import datasets, models, transforms
# from torchsummary import summary #network summary

# imported by us
import os
from torch.utils.data import Dataset
from argparse import ArgumentParser
import time
from model.MalConv import MalConv
from utils.MalDataset import MalDataset
import tarfile
from utils import cnn_training

#---------------------------------- DEFINITION OF THE CLASSES ----------------------------------------

def main():
  parser = ArgumentParser()
  parser.add_argument('--batch_size', help='The batch size', type=int, default=256)
  parser.add_argument('--model_save_path', help='Folder where the model will be saved', type=str, default=None)
  parser.add_argument('--model_eval_path', help='Folder where the model will be taken for evaulate it', type=str, default=None)
  parser.add_argument('--perc_validation', help='Percentage of the validation set compared to the total dataset used for training', type=float, default=0.3)
  parser.add_argument('--n_epochs', help='Number of epochs in the training phase', type=int, default=50)
  parser.add_argument('--early_stopping', help='Max number of epochs without an improvement on the validation_accuracy', type=int, default=0)
  parser.add_argument('--file_dim', help='Max dim of the input file for the model (in MB)', type=int, default=2)
  parser.add_argument('--verbose', help='Show the progress during the training phase', type=int, default=1)
  parser.add_argument('--dataset_path', help='Dataset Tar Location (no GZ compression)', type=str, default=None)
  args = parser.parse_args()
  print("\nModel paramteres:\n")
  print("Batch size: ",args.batch_size)
  print("Folder where the model will be saved: ",args.model_save_path)
  print("Folder where the model will be taken: ",args.model_eval_path)
  print("Percentage of the validation set compared to the total dataset used for training: ",args.perc_validation)
  print("Number of epochs in the training phase: ",args.n_epochs)
  if args.early_stopping==0:
    early_stopping=args.n_epochs
  else:
    early_stopping=args.early_stopping
  print("Early stopping on the val accuracy: ",early_stopping)
  if args.file_dim==2:
    file_dim=2**21
    print("Model: MalConv (file dim of ",file_dim," byte)")
  else:
    file_dim=2**20
    print("Model: emberMalConv (file dim of ",file_dim," byte)")
  print("Verbose: ", args.verbose==1)


  
  print("\n")

  #---------------------------------- PREPARATION OF THE DATASET ----------------------------------------
  file_list_train=[]
  tar = tarfile.open(args.dataset_path,"r")
  i=0


  for member in tar.getmembers():
      info_member=member.get_info()
      if info_member['size']>0:   #Ã¨ un file e non una dir
        name_splitted=info_member['name'].split('/')
        train_or_test=name_splitted[-3]
        malware_type=name_splitted[-2]
        if(train_or_test=='train'):
            if(malware_type=='benign'):
                file_list_train.append((member,0))
            else:
                file_list_train.append((member,1))
  tar.close()
  
  train_dataset = MalDataset(path_tar=args.dataset_path,member_list=file_list_train,first_n_byte=file_dim)

  train_transform = transforms.Compose([
  transforms.ToTensor(),
  ])
  train_dataset.transform = train_transform

  """test_transform = transforms.Compose([
  transforms.ToTensor(),
  ])
  test_dataset.transform = test_transform"""

  perc_split=args.perc_validation
  dataset_length=len(train_dataset)
  train_data, val_data = random_split(train_dataset, [round(dataset_length*(1-perc_split)), round(dataset_length*perc_split)])
  print("The dataset length is : ",dataset_length)
  print("The train_dataset length is : ",round(dataset_length*(1-perc_split)))
  print("The valid_dataset length is : ",round(dataset_length*perc_split))
  batch_size=args.batch_size

  train_loader = DataLoader(train_data, batch_size=batch_size,num_workers=1)
  valid_loader = DataLoader(val_data, batch_size=batch_size,num_workers=1)
  # test_loader = DataLoader(test_dataset, batch_size=batch_size,shuffle=True)

  #---------------------------------- PREPARATION OF THE MODEL ----------------------------------------
  MalConv_net=MalConv(input_length=file_dim)

  n_epochs = args.n_epochs
  criterion =nn.BCELoss()
  optimizer = optim.Adam(MalConv_net.parameters())
  # Selecting the device on apple silicon
  if torch.backends.mps.is_available():
    device=torch.device('mps')
  elif torch.cuda.is_available():
    device=torch.device('cuda:0')
  else:
    device=torch.device('cpu')

  print(f"Using device: {device}")
  
  print("Is the model on the GPU? ",next(MalConv_net.parameters()).is_mps or torch.cuda.is_available())

  #---------------------------------- TRAINING PHASE ----------------------------------------
  if args.model_save_path is not None:
    train_loss = []
    train_acc = []
    val_loss = []
    val_acc = []
    st = time.time()
    i=0
    max=0
    early_stop_i=0
    for epoch in range(n_epochs):
        st_epoch = time.time()
        print("\n\n##################### Epoch {} #####################".format(epoch))
        train_loss, train_acc = cnn_training.train_model(model=MalConv_net, device=device, phase='train', dataloaders=train_loader, criterion=criterion, optimizer=optimizer,loss_arr=train_loss, acc_arr=train_acc,verbose=args.verbose)
        print("\nValidation\n")
        val_loss, val_acc = cnn_training.train_model(model=MalConv_net, device=device, phase='validation', dataloaders=train_loader, criterion=criterion, optimizer=optimizer,loss_arr=val_loss, acc_arr=val_acc,verbose=args.verbose)
        print("\n\nTrain_loss: {:.3f}, Train_acc: {:.3f}".format(np.mean(train_loss), np.mean(train_acc)))
        print("Validation_loss: {:.3f}, Validation_acc: {:.3f}".format(np.mean(val_loss), np.mean(val_acc)))
        et_epoch = time.time()
        print('Execution time for epoch ', i,' :', et_epoch-st_epoch, 'seconds')

        if np.mean(val_acc)>=max:
          max=np.mean(val_acc)
          early_stop_i=0
          torch.save(MalConv_net, os.path.join(args.model_save_path,"best_model.pth.tar"))
          print("Best model saved")
        else:
          early_stop_i+=1
        if early_stop_i==early_stopping:
          print("EARLY STOPPING")
          break
    et = time.time()
    elapsed_time = et - st
    print('Execution time:', elapsed_time, 'seconds')

    #Save the model
    torch.save(MalConv_net, os.path.join(args.model_save_path,"model.pth.tar"))

  #---------------------------------- EVALUATION PHASE ----------------------------------------
  if args.model_eval_path is not None:
    #Load the models

    model = torch.load(args.model_eval_path)
    model.eval()

if __name__ == '__main__':
    main()