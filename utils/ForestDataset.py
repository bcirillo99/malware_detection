import numpy as np
import tarfile
from ember.features import PEFeatureExtractor
import pandas as pd
from argparse import ArgumentParser

def load_forest_dataset(dataset_path,set):
    file_list=list()
    label_list=list()
    with tarfile.open(dataset_path,'r') as tar:
        for file in tar.getmembers():
            if file.isfile():
                name_splitted=file.name.split('/')
                train_or_test=name_splitted[-3]
                malware_type=name_splitted[-2]
                if set==train_or_test:
                    file_extracted = tar.extractfile(file)
                    print('Extracting {}'.format(file.name))
                    bytes = file_extracted.read()
                    features=get_ember_features(bytes)
                    file_list.append(features)
                    if malware_type=="benign":
                        label_list.append(0)
                    else:
                        label_list.append(1)
    return np.array(file_list), np.array(label_list)

def get_ember_features(bytes, dst=None):
    extractor = PEFeatureExtractor()
    features = [float(value) for value in extractor.feature_vector(bytes)]
    return features

def extract_feature_dataset(dataset_path,save_train_path,save_test_path,save_val_path):
    if save_train_path is not None:
        X_train,y_train=load_forest_dataset(dataset_path,'train')
        df_train=pd.DataFrame(X_train.tolist(),index=y_train.tolist())
        df_train.to_csv(save_train_path)

    if save_val_path is not None:
        X_val,y_val=load_forest_dataset(dataset_path,'validation')
        df_val=pd.DataFrame(X_val.tolist(),index=y_val.tolist())
        df_test.to_csv(save_test_path)

    if save_test_path is not None:
        X_test,y_test=load_forest_dataset(dataset_path,'test')
        df_test=pd.DataFrame(X_test.tolist(),index=y_test.tolist())
        df_val.to_csv(save_val_path)
    
def load_extracted_features(training_csv,test_csv):
    X_train = y_train = X_test = y_test = None
    if training_csv is not None:
        training_set=pd.read_csv(training_csv).to_numpy()
        y_train=training_set[:,0]
        X_train=training_set[:,range(1,len(training_set[0]))]
    if test_csv is not None:
        test_set=pd.read_csv(test_csv).to_numpy()
        y_test=test_set[:,0]
        X_test=test_set[:,range(1,len(test_set[0]))]
    return X_train, y_train, X_test, y_test
            
    
if __name__=='__main__':
    parser = ArgumentParser()
    parser.add_argument('--dataset_path',help='Dataset Tar Location (no GZ compression)',type=str, default=None)
    parser.add_argument('--save_train_path', help='Path to which the training set features are saved', type=str, default=None)
    parser.add_argument('--save_test_path', help='Path to which the test set features are saved',type=str, default=None)
    parser.add_argument('--save_val_path', help='Path to which the validation set features are saved',type=str, default=None)
    args = parser.parse_args()
    extract_feature_dataset(args.dataset_path,args.save_train_path,args.save_test_path,args.save_val_path)