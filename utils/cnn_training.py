import os
import time
import numpy as np
import torch
import tarfile
from utils.TarDataset import TarDataset
from torch.utils.data import DataLoader

def get_device(verbose=True):
    if torch.backends.mps.is_available():
        device=torch.device('mps')
    elif torch.cuda.is_available():
        device=torch.device('cuda:0')
    else:
        device=torch.device('cpu')
    if(verbose==True):
        print(f"Using device: {device}")
    return device


def get_loaders_train_from_tar(path_tar, file_dim, batch_size, padding=False, transform=None, verbose=True):
    file_list_train = get_file_list(path_tar, 'train')
    file_list_val = get_file_list(path_tar, 'validation')
    data_train = TarDataset(path_tar=path_tar,member_list=file_list_train,first_n_byte=file_dim, padding=padding, transform=transform)
    data_val = TarDataset(path_tar=path_tar,member_list=file_list_val,first_n_byte=file_dim, padding=padding, transform=transform)

    if(verbose==True):
        print(f"The dataset length is : {len(data_train)+len(data_val)}")
        print(f"The train_dataset length is : {len(data_train)}")
        print(f"The valid_dataset length is : {len(data_val)}",)
    train_loader = DataLoader(data_train, batch_size=batch_size, num_workers=1, shuffle=True)
    val_loader = DataLoader(data_val, batch_size=batch_size, num_workers=1, shuffle=True)
    return train_loader, val_loader
    


def get_file_list(path_tar, set):
    file_list=[]
    tar = tarfile.open(path_tar,"r")
    for member in tar.getmembers():
        info_member=member.get_info()
        if info_member['size']>0:   #Ã¨ un file e non una dir
            name_splitted=info_member['name'].split('/')
            train_or_val=name_splitted[-3]
            malware_type=name_splitted[-2]
            if(train_or_val==set):
                if(malware_type=='benign'):
                    file_list.append((member,0))
                else:
                    file_list.append((member,1))
           
    tar.close()
    return file_list

def train_model(model, criterion, optimizer, device, dataloader, epochs, model_save_path, early_stopping=0, verbose=True):
    model=model.to(device)
    criterion=criterion.to(device)
    max_acc=0
    count_earlystopping=0
    for i in range(epochs):
        print(f"\n\n##################### Train Epoch {i} #####################")
        time_start=time.time()
        for phase in ['train', 'validation']:
            
            loss_epoch=[]
            acc_epoch = []

            ####-----------------SWITCHING MODE------------------
            print(f"------------{phase.upper()} PHASE-------------")
            if(phase=='train'):
                model.train()
            elif phase == 'validation':
                model.eval()

            ###----------------COMPUTING BATCHES-------------------------
            count=0
            for inputs, labels in dataloader[phase]:
                loss_batch=[]
                acc_batch=[]
                
                inputs = inputs.to(device)
                labels = labels.to(device)
                
                print(f"Compute batch {count}/{len(dataloader[phase])}=>", end="")
                outputs = model(inputs)
                loss = criterion(outputs, labels)
                if phase == 'train':
                    optimizer.zero_grad()
                    loss.backward()
                    optimizer.step()
                count+=1
                # print((torch.cuda.memory_summary(device)))
                labels=labels.detach().cpu().numpy().astype(int)
                outputs=outputs.detach().cpu().numpy()

                acc_batch.extend(list(labels)==np.around(outputs).astype(int))
                loss_batch.append(loss.detach().cpu().numpy())

                loss_batch_mean=round(np.mean(loss_batch),3)
                acc_batch_mean=round(np.mean(acc_batch),3)
                if verbose==True:
                    print(f"{phase}_loss: {str(loss_batch_mean)}, {phase}_acc: {str(acc_batch_mean)}, ", end="")
                    class0_acc, class1_acc=compute_class_accuracy(outputs, labels)
                    print(f"Class 0 accuracy ({class0_acc.count(1)}/{len(class0_acc)}): {str(round(np.mean(class0_acc),3))}, Class 1 accuracy ({class1_acc.count(1)}/{len(class1_acc)}): {str(round(np.mean(class1_acc),3))}")

                loss_epoch.append(loss_batch_mean)
                acc_epoch.append(acc_batch_mean)

            #-------COMPUTING LOSS-----
            loss_epoch_mean=round(np.mean(loss_epoch),3)
            acc_epoch_mean=round(np.mean(acc_epoch),3)
            print(f"#####EPOCH {i}====>>>>{phase}_loss: {str(loss_epoch_mean)}, {phase}_acc: {str(acc_epoch_mean)}####")
            
            ####---------EARLY STOPPING----------
            if(phase=='validation'):
                if(acc_epoch_mean>max_acc):
                    print(f"#######  Found Best Model. Saving to {model_save_path}")
                    count_earlystopping=0
                    torch.save(model, os.path.join(model_save_path,"model.pth.tar"))
                    max_acc=acc_epoch_mean
                else:
                    count_earlystopping=count_earlystopping+1
                    print("###############   Worse Model. Not Saved", end="")
                    if(early_stopping!=0):
                        print(f"EarlyStopping {count_earlystopping}/{early_stopping}")
                        if(count_earlystopping==early_stopping):
                            print(f"###########  TRAINING EARLY STOPPED  {count_earlystopping}/{early_stopping}###########")
                            return
                    print()
        print(f"Time Elapsed: {time.time()- time_start}")
        print("\n\n") 
      
    torch.save(model, os.path.join(model_save_path,"model.pth.tar"))
          


def compute_class_accuracy(outputs, labels):
    count0_right=0
    count1_right=0
    class0_acc=[]
    class1_acc=[]
    for i in range(0, len(outputs)):
        if(labels[i][0]==1):
            if(labels[i][0]==round(outputs[i][0])):
                count1_right=count1_right+1
                class1_acc.append(1)
            else:
                class1_acc.append(0)
        if(labels[i][0]==0):

            if(labels[i][0]==round(outputs[i][0])):
                count0_right=count0_right+1
                class0_acc.append(1)
            else:
                class0_acc.append(0)
    return class0_acc, class1_acc


def model_evaluate(model, dataloader, device, criterion, verbose):   #return acc and loss lists on loader
    print("########## EVALUATING ON DATALOADER #############")
    model=model.to(device)
    model.eval()
    loss_list=[]
    acc_list=[]
    count=0
    for inputs, labels in dataloader:
        loss_batch=[]
        acc_batch=[]
        print(f"Compute batch {count}/{len(dataloader)}=>", end="")
        inputs = inputs.to(device)
        labels = labels.to(device)
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        count+=1
        labels=labels.detach().cpu().numpy().astype(int)
        outputs=outputs.detach().cpu().numpy()
        acc_batch.extend(list(labels)==np.around(outputs).astype(int))
        loss_batch.append(loss.detach().cpu().numpy())

        loss_batch_mean=round(np.mean(loss_batch),3)
        acc_batch_mean=round(np.mean(acc_batch),3)
        if verbose==True:
            print(f"Evaluating_loss: {str(loss_batch_mean)}, Evaluating_acc: {str(acc_batch_mean)}, ", end="")
            class0_acc, class1_acc=compute_class_accuracy(outputs, labels)
            print(f"Class 0 accuracy ({class0_acc.count(1)}/{len(class0_acc)}): {str(round(np.mean(class0_acc),3))}, Class 1 accuracy ({class1_acc.count(1)}/{len(class1_acc)}): {str(round(np.mean(class1_acc),3))}")

        loss_list.append(loss_batch_mean)
        acc_list.append(acc_batch_mean)
    return loss_list, acc_list

    