
import torch.nn as nn
import torch.optim as optim
from torchvision import models, transforms
from torchvision.models import resnet50, ResNet50_Weights
from argparse import ArgumentParser
from utils.BinToImg import BinToImg
from utils import cnn_training


def main():
  parser = ArgumentParser()
  parser.add_argument('--batch_size', help='The batch size', type=int, default=256)
  parser.add_argument('--model_save_path', help='Folder where the model will be saved', type=str, default=None)
  parser.add_argument('--n_epochs', help='Number of epochs in the training phase', type=int, default=50)
  parser.add_argument('--early_stopping', help='Max number of epochs without an improvement on the validation_accuracy', type=int, default=0)
  parser.add_argument('--file_dim', help='Max dim of the input file for the model (in MB)', type=int, default=2)
  parser.add_argument('--verbose', help='Show the progress during the training phase', type=int, default=1)
  parser.add_argument('--dataset_path', help='Dataset Tar Location (no GZ compression)', type=str, default=None)
  args = parser.parse_args()
  print("\nModel paramteres:\n")
  print("Batch size: ",args.batch_size)
  print("Folder where the model will be saved: ",args.model_save_path)
  print("Number of epochs in the training phase: ",args.n_epochs)
  if args.file_dim==2:
      file_dim=2**21
      print("Model: MalConv (file dim of ",file_dim," byte)")
  else:
      file_dim=2**20
      print("Model: emberMalConv (file dim of ",file_dim," byte)")
  print("Verbose: ", args.verbose==1)
  print("\n")


  # target_transform = transforms.Lambda(lambda x: BinToImg().forward(x))

  img_transform=BinToImg()
  data_transforms_bin = transforms.Compose([
      img_transform,
      transforms.Grayscale(num_output_channels=3),
      transforms.Resize((224,224)), 
      transforms.ToTensor()
      ])
  train_loader=cnn_training.get_loader_from_tar(args.dataset_path, 'train', file_dim, args.batch_size, padding=False, verbose=True, transform=data_transforms_bin)
  val_loader=cnn_training.get_loader_from_tar(args.dataset_path, 'validation', file_dim, args.batch_size, padding=False, verbose=True, transform=data_transforms_bin)
  dataloader={
    'train': train_loader,
    'validation': val_loader
  }
 




  ##-----------------------MODEL--------------
  model = models.resnet50(weights=ResNet50_Weights.DEFAULT)
  # Replacing the last fully-connected layer
  model.fc = nn.Sequential(
                nn.Linear(2048, 128),
                nn.ReLU(inplace=True),
                nn.Linear(128, 1), #2 is the number of classes
                nn.Sigmoid())
  criterion = nn.BCELoss()
  optimizer = optim.Adam(model.fc.parameters())


  device=cnn_training.get_device()
  ##----------------------------TRAINING
  
  cnn_training.train_model(model, criterion, optimizer, device, dataloader,args.n_epochs,  args.model_save_path, early_stopping=args.early_stopping )


if __name__ == '__main__':
  main()
