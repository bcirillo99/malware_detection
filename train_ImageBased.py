
import torch.nn as nn
import torch.optim as optim
from torchvision import models, transforms
from torchvision.models import resnet50, ResNet50_Weights
from argparse import ArgumentParser
from utils.BinToImg import BinToImg
from utils import cnn_training


def main():
  parser = ArgumentParser()
  parser.add_argument('--batch_size', help='The batch size', type=int, default=256)
  parser.add_argument('--model_save_path', help='Folder where the model will be saved', type=str, default=None)
  parser.add_argument('--model_eval_path', help='Folder where the model will be taken for evaulate it', type=str, default=None)
  parser.add_argument('--perc_validation', help='Percentage of the validation set compared to the total dataset used for training', type=float, default=0.3)
  parser.add_argument('--n_epochs', help='Number of epochs in the training phase', type=int, default=50)
  parser.add_argument('--early_stopping', help='Max number of epochs without an improvement on the validation_accuracy', type=int, default=0)
  parser.add_argument('--file_dim', help='Max dim of the input file for the model (in MB)', type=int, default=2)
  parser.add_argument('--verbose', help='Show the progress during the training phase', type=int, default=1)
  parser.add_argument('--dataset_path', help='Dataset Tar Location (no GZ compression)', type=str, default=None)
  args = parser.parse_args()
  print("\nModel paramteres:\n")
  print("Batch size: ",args.batch_size)
  print("Folder where the model will be saved: ",args.model_save_path)
  print("Folder where the model will be taken: ",args.model_eval_path)
  print("Percentage of the validation set compared to the total dataset used for training: ",args.perc_validation)
  print("Number of epochs in the training phase: ",args.n_epochs)
  if args.file_dim==2:
      file_dim=2**21
      print("Model: MalConv (file dim of ",file_dim," byte)")
  else:
      file_dim=2**20
      print("Model: emberMalConv (file dim of ",file_dim," byte)")
  print("Verbose: ", args.verbose==1)
  print("\n")


  target_transform = transforms.Lambda(lambda x: BinToImg().forward(x))
  data_transforms_bin = transforms.Compose([
      target_transform,
      transforms.Grayscale(num_output_channels=3),
      transforms.Resize((224,224)), 
      transforms.ToTensor()
      ])
  dataloader=cnn_training.get_loaders_from_tar(args.dataset_path, file_dim, args.batch_size, args.perc_validation, padding=False, verbose=True, transform=data_transforms_bin)
  device=cnn_training.get_device()




  ##-----------------------MODEL--------------
  model = models.resnet50(weights=ResNet50_Weights.DEFAULT)
  # Replacing the last fully-connected layer
  model.fc = nn.Sequential(
                nn.Linear(2048, 128),
                nn.ReLU(inplace=True),
                nn.Linear(128, 2), #2 is the number of classes
                nn.Softmax(dim=1))
  criterion = nn.CrossEntropyLoss()
  optimizer = optim.Adam(model.fc.parameters())

  ##----------------------------TRAINING
  cnn_training.train_model(model, criterion, optimizer, device, dataloader,args.n_epochs,  args.model_save_path, early_stopping=5 )


if __name__ == '__main__':
  main()
